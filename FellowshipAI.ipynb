{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3df936-47b7-4fbc-82ec-eb693a13d0e3",
   "metadata": {},
   "source": [
    "# Fellowship AI Application "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ac9491-8b47-43ed-a955-25afb2a28756",
   "metadata": {},
   "source": [
    "### By: Devon Bolen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db249d-97ee-4e53-a908-88d5693bbbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe('spacytextblob')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14535725-82ba-4604-a0d9-5e4e82b85380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data in\n",
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df2fd7e8-ab5a-49f8-bea3-e830fff0e66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21795dd-7e3c-4047-900f-67ca69f3017d",
   "metadata": {},
   "source": [
    "# Basic Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db6a19-71dc-4685-ac65-e638221a3d98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Results of EDA**\n",
    "- Total records to start: 50,000\n",
    "- 2 features: One categorical, one text data.\n",
    "- Value counts for sentiment field reflect that the data is equally distributed across. Each category has 25,000 records. \n",
    "- No null values in the data.\n",
    "- Found and later removed 418 duplicate rows.\n",
    "- Remaining records: 49,582\n",
    "- Reviewed word count of sentiment values to see if the word count varied by sentiment. It does not.\n",
    "\n",
    "**Normally with more robust datasets, I would also do the following:**\n",
    "- Remove columns with single values\n",
    "- Calculate percentage of unique values for each column. For those with very little percentage, I would consider removing the column or encode it. Remove columns with very low variance.\n",
    "- Make sure the index is a unique identifier if not already\n",
    "- Review and change datatypes (if needed)\n",
    "- Rename columns (if needed)\n",
    "- Perform over or under sampling of the data if it is imbalanced\n",
    "- Add new columns based on data from existing columns (if the data would benefit)\n",
    "- Remove test data (test entries)\n",
    "- Remove null values or replace nulls with mean or median.\n",
    "- Investigate outliers (boxplot, histogram for distribution). Remove outliers if necessary.\n",
    "- Correlation plot, heatmap for numeric values\n",
    "- Chi squared for correlating categorical variables\n",
    "- Encode categorical variables if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc67ff20-cbd0-4763-958e-3b1326e824cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e01b5c-48bf-4bd1-a1b5-61d158d84f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary stats\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b6a462-8d5a-4b35-9f18-b9efc53be92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target value counts\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f542158-b10d-4660-bb21-55f658b4cc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting value counts\n",
    "df['sentiment'].value_counts()[:].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01cae88a-4218-4096-b70c-f255ad247dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d73c50-553a-4939-b59a-71b9ccce15a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating total null values in features\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82dc3bfd-fc50-4664-8613-6e80e9c6d8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232.84932\n",
      "229.46456\n"
     ]
    }
   ],
   "source": [
    "# Looking at average number of words for each movie review for positive and negative reviews\n",
    "df['word_count'] = df['review'].apply(lambda x: len(str(x).split()))\n",
    "print(df[df['sentiment']=='positive']['word_count'].mean()) #Positive reviews\n",
    "print(df[df['sentiment']=='negative']['word_count'].mean()) #Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "632c96d1-2dc8-4a46-9d57-e191c3ef3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing word_count column\n",
    "df=df.drop(columns=['word_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e0a843-c421-4fc3-a211-6be6d54bac3b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dda740-ff98-4594-a77e-aa50b36bd434",
   "metadata": {},
   "source": [
    "**Preprocessing involves:**\n",
    "- Convert categorical variables to numeric\n",
    "- Removed duplicates\n",
    "- Reset index\n",
    "- Lowercased text\n",
    "- Removed stopwords\n",
    "- Removed additional whitespace\n",
    "- Removed non alphabetic characters\n",
    "- Remove words with 2 characters or less. Noticed typos or words such as \"br\" \"oz\" in analysis.\n",
    "- Lemmatized text\n",
    "\n",
    "**I decided to lemmatize instead of stem for below reasons:**\n",
    "- More accurate than stemming\n",
    "- Keeps context by looking at structure and syntax of word to remove inflectional endings only and return the base form\n",
    "- Stemming can sometimes chop off the end of the words\n",
    "- In this analysis, the meaning of the word is important in predicting sentiment, therefore I would prefer to use lemmatization vs stemming in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3e1454b-e9ec-4d46-803f-ceb7f117d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment values to binary using sklearns label encoder.\n",
    "df['label'] = label_encoder.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fab5f886-dc48-4191-b1a4-ce609a2d9fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count duplicates (418)\n",
    "len(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54cbca89-abdc-4223-89d4-9c999a5c594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f45b0aac-c16a-4acf-bbee-43db51ba6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df=df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4061c20c-2068-40ce-9cb8-b70005129f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing text, replacing apostrophes with empty string, removing extra whitespace, removing stopwords, lemmatizing, removing words with only two characters\n",
    "# Adding in polarity values to see if this feature adds to model performance\n",
    "def preprocess(text):\n",
    "    text = text.lower().replace(\"'\",\"\")\n",
    "    text = re.sub(\"[^a-zA-Z]+\",\" \",text)\n",
    "    text = re.sub(' +',' ',text)\n",
    "    text = \" \".join(x for x in text.split() if x not in stopwords.words('english') and len(x) > 2)\n",
    "    doc = nlp(text)\n",
    "    return \" \".join(lemmatizer.lemmatize(w) for w in word_tokenize(text)), doc._.blob.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a0039a3-f474-4bad-ac8e-5a565b0bc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "df['review_preprocessed'],df['polarity']=zip(*df['review'].apply(preprocess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb21bd02-ec74-41fe-8159-9ebe717d662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelevant columns for modeling\n",
    "newdf = df.drop(columns=['review','sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc03adba-ae32-4eaf-afbf-1b48d8a8e1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review_preprocessed</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer mentioned watching episode youll ...</td>\n",
       "      <td>0.041946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>0.125980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>0.285317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>-0.060937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>0.234551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                review_preprocessed  polarity\n",
       "0      1  one reviewer mentioned watching episode youll ...  0.041946\n",
       "1      1  wonderful little production filming technique ...  0.125980\n",
       "2      1  thought wonderful way spend time hot summer we...  0.285317\n",
       "3      0  basically there family little boy jake think t... -0.060937\n",
       "4      1  petter matteis love time money visually stunni...  0.234551"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4f197b-ee62-4030-84be-6eedc97d53a4",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "20bbf207-9741-4e82-a40e-630927e12bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training sets. Using 80/20 to grab 80% of data for training sets.\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(newdf['review_preprocessed'],newdf['label'], test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fb3fb819-8aac-4f63-bbf9-ce012b8aaf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the validation and test sets. Using 50% test size to grab 10% data for validation and 10% of data for test.\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8c4c24eb-2c60-4890-a4ae-6a67c3ab50c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39665,)\n",
      "(39665,)\n",
      "(4958,)\n",
      "(4958,)\n",
      "(4959,)\n",
      "(4959,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the shape of the data after splitting\n",
    "print(X_train.shape), print(y_train.shape)\n",
    "print(X_valid.shape), print(y_valid.shape)\n",
    "print(X_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "390817f9-9eac-45b5-97a8-4c9093d88e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TFIDF Vectorizer to fit the data. I prefer this over Count Vec because it calculates IDF to account for term importance instead of just frequency.\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_valid_vectors_tfidf = tfidf_vectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae3dc5-808b-4738-97ce-85a2b3e82b90",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7a801087-82e1-4e86-86dc-e7eb3bdf2358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89      2498\n",
      "           1       0.88      0.91      0.89      2460\n",
      "\n",
      "    accuracy                           0.89      4958\n",
      "   macro avg       0.89      0.89      0.89      4958\n",
      "weighted avg       0.89      0.89      0.89      4958\n",
      "\n",
      "Confusion Matrix: [[2179  319]\n",
      " [ 213 2247]]\n",
      "AUC: 0.9592970311208315\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf=LogisticRegression()\n",
    "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "#Predict y value for test dataset\n",
    "y_predict = lr_tfidf.predict(X_valid_vectors_tfidf)\n",
    "y_prob = lr_tfidf.predict_proba(X_valid_vectors_tfidf)[:,1]\n",
    "\n",
    "# Printing metrics\n",
    "print(classification_report(y_valid,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_valid, y_predict))\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c5b16-642f-4419-a527-4e0570936422",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7df15a28-26a2-4995-8eac-283a1a53b58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      2498\n",
      "           1       0.87      0.86      0.86      2460\n",
      "\n",
      "    accuracy                           0.86      4958\n",
      "   macro avg       0.86      0.86      0.86      4958\n",
      "weighted avg       0.86      0.86      0.86      4958\n",
      "\n",
      "Confusion Matrix: [[2179  319]\n",
      " [ 355 2105]]\n",
      "AUC: 0.9370317392125083\n"
     ]
    }
   ],
   "source": [
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "#Predict y value for test dataset\n",
    "y_predict = nb_tfidf.predict(X_valid_vectors_tfidf)\n",
    "y_prob = nb_tfidf.predict_proba(X_valid_vectors_tfidf)[:,1]\n",
    "\n",
    "# Printing metrics\n",
    "print(classification_report(y_valid,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_valid, y_predict))\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0665cd97-02a8-4c61-a900-86f6de703b89",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddf25af8-e36a-44bc-98ba-7de8446ede0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77      2498\n",
      "           1       0.74      0.85      0.80      2460\n",
      "\n",
      "    accuracy                           0.78      4958\n",
      "   macro avg       0.79      0.78      0.78      4958\n",
      "weighted avg       0.79      0.78      0.78      4958\n",
      "\n",
      "Confusion Matrix: [[1777  721]\n",
      " [ 358 2102]]\n",
      "AUC: 0.8559807195349777\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train_vectors_tfidf, y_train)\n",
    "y_predict = classifier.predict(X_valid_vectors_tfidf)\n",
    "y_prob = classifier.predict_proba(X_valid_vectors_tfidf)[:,1]\n",
    "\n",
    "# Printing metrics\n",
    "print(classification_report(y_valid,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_valid, y_predict))\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a621bf84-7746-46f4-acf0-258a9e90d52e",
   "metadata": {},
   "source": [
    "#### GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d086da6e-7d7e-45e4-b495-64d800e95267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.79      2498\n",
      "           1       0.76      0.86      0.81      2460\n",
      "\n",
      "    accuracy                           0.80      4958\n",
      "   macro avg       0.80      0.80      0.80      4958\n",
      "weighted avg       0.80      0.80      0.80      4958\n",
      "\n",
      "Confusion Matrix: [[1847  651]\n",
      " [ 342 2118]]\n",
      "AUC: 0.8870274268195043\n"
     ]
    }
   ],
   "source": [
    "gradient_booster = GradientBoostingClassifier(learning_rate=0.1)\n",
    "gradient_booster.fit(X_train_vectors_tfidf,y_train)\n",
    "y_predict = gradient_booster.predict(X_valid_vectors_tfidf)\n",
    "y_prob = gradient_booster.predict_proba(X_valid_vectors_tfidf)[:,1]\n",
    "\n",
    "# Printing metrics\n",
    "print(classification_report(y_valid,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_valid, y_predict))\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a17d0b-d085-495c-99e7-c0745485ba2c",
   "metadata": {},
   "source": [
    "**Choosing the best model:**\n",
    "- Logistic regression had the highest accuracy of .89 and higher f1 score than other models. EXAPND ON THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0ef4f5c8-b970-4938-b5a7-fc1952b33241",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectors_tfidf=tfidf_vectorizer.transform(X_test)\n",
    "y_predict = lr_tfidf.predict(X_test_vectors_tfidf)      \n",
    "y_prob = lr_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3b11f181-9e01-40f4-a797-db38042c717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest=pd.DataFrame(X_test)\n",
    "dftest['label'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "78035e8c-ca93-42da-b240-18dae0611e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_preprocessed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ernst lubitsch contribution american cinema en...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jason lee well give doggy movie fleeting promi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>far one worst movie ever seen poor special eff...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>offensive liked movie probably never opened bi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>never felt need add review website sat film fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 review_preprocessed  target\n",
       "0  ernst lubitsch contribution american cinema en...       1\n",
       "1  jason lee well give doggy movie fleeting promi...       0\n",
       "2  far one worst movie ever seen poor special eff...       0\n",
       "3  offensive liked movie probably never opened bi...       0\n",
       "4  never felt need add review website sat film fe...       1"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest['predict_prob']= y_prob\n",
    "dftest['target']= y_predict\n",
    "final=dftest[['review_preprocessed','target']].reset_index(drop=True)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "05387eff-39b9-422a-9cfd-a7cd51e46b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      2441\n",
      "           1       0.89      0.90      0.90      2518\n",
      "\n",
      "    accuracy                           0.89      4959\n",
      "   macro avg       0.89      0.89      0.89      4959\n",
      "weighted avg       0.89      0.89      0.89      4959\n",
      "\n",
      "Confusion Matrix: [[2156  285]\n",
      " [ 243 2275]]\n",
      "AUC: 0.958917343671245\n"
     ]
    }
   ],
   "source": [
    "# Printing metrics for final test evaluation\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7705cb88-1fb2-406a-be22-94e2b0ae7ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_preprocessed</th>\n",
       "      <th>label</th>\n",
       "      <th>predict_prob</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5411</th>\n",
       "      <td>ernst lubitsch contribution american cinema en...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989290</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28007</th>\n",
       "      <td>jason lee well give doggy movie fleeting promi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22649</th>\n",
       "      <td>far one worst movie ever seen poor special eff...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11342</th>\n",
       "      <td>offensive liked movie probably never opened bi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32070</th>\n",
       "      <td>never felt need add review website sat film fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     review_preprocessed  label  predict_prob  \\\n",
       "5411   ernst lubitsch contribution american cinema en...      1      0.989290   \n",
       "28007  jason lee well give doggy movie fleeting promi...      0      0.094542   \n",
       "22649  far one worst movie ever seen poor special eff...      0      0.000019   \n",
       "11342  offensive liked movie probably never opened bi...      0      0.056260   \n",
       "32070  never felt need add review website sat film fe...      0      0.550001   \n",
       "\n",
       "       target  \n",
       "5411        1  \n",
       "28007       0  \n",
       "22649       0  \n",
       "11342       0  \n",
       "32070       1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91014dc-886f-4e05-b078-1030cb5fcd3c",
   "metadata": {},
   "source": [
    "# Ways to improve model\n",
    "- Try lemmatizing first, then stemming and see if model performance changes\n",
    "- Try stemming alone\n",
    "- Add more data - using Spacy library you can add entitiy labels (NER), noun chunks, polarity values, parts of speech tags and dependencies, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e471fd49-99ff-48b6-9618-0ce7604697d2",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1cd24-97be-4483-9519-5e1896df6aec",
   "metadata": {},
   "source": [
    "### Modeling using Polarity Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "56e1a53d-27f5-4363-a160-2dc179d7da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not the most ideal feature to use for this particular dataset as a single feauture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551debf6-a2c5-402b-83d6-7958fa51e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training sets. Using 80/20 to grab 80% of data for training sets.\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(newdf['polarity'], newdf['label'], test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0cafdb-e81a-4240-98d0-6c96acd92cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the validation and test sets. Using 50% test size to grab 10% data for validation and 10% of data for test.\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced1ff1-ce73-4a11-95e1-716648f491da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train.to_list(),(-1,1))\n",
    "X_valid = np.reshape(X_valid.to_list(),(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef36fda-33f0-4eb6-9e54-21607b666f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39665,)\n",
      "(39665,)\n",
      "(4958,)\n",
      "(4958,)\n",
      "(4959,)\n",
      "(4959,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the shape of the data after splitting\n",
    "print(X_train.shape), print(y_train.shape)\n",
    "print(X_valid.shape), print(y_valid.shape)\n",
    "print(X_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec725a-0eb4-420b-a379-d568a20ea910",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f42e6-70c0-455c-bf77-167d51e9f16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      2498\n",
      "           1       0.76      0.77      0.77      2460\n",
      "\n",
      "    accuracy                           0.77      4958\n",
      "   macro avg       0.77      0.77      0.77      4958\n",
      "weighted avg       0.77      0.77      0.77      4958\n",
      "\n",
      "Confusion Matrix: [[1907  591]\n",
      " [ 564 1896]]\n",
      "AUC: 0.8396508263521386\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr.fit(X_train1, y_train)  \n",
    "#Predict y value for test dataset\n",
    "y_predict = lr.predict(X_valid1)\n",
    "y_prob = lr.predict_proba(X_valid1)[:,1]\n",
    "\n",
    "# Printing metrics\n",
    "print(classification_report(y_valid,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_valid, y_predict))\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
